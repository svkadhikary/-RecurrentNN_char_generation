{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10cd4f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0e6173",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"shakespeare.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea8f4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text: 94238 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')[37:]\n",
    "print(f'length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec704285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From fairest creatures we desire increase,\n",
      "That thereby beauty's rose might never die,\n",
      "But as the riper should by time decease,\n",
      "His tender heir might bear his memory:\n",
      "But thou contracted to thine own bright eyes,\n",
      "Feed'st thy light's flame with self-s\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83ce4829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocabulary size: 61\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f'total vocabulary size: {len(vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b85fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the string lookup layer\n",
    "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "549eaec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[36, 37, 38, 39, 40], [41, 42, 43]]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = ['abcde', 'fgh']\n",
    "chars = tf.strings.unicode_split(example_text, input_encoding='UTF-8')\n",
    "\n",
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2155db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create chars from ids\n",
    "chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3a8987f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e'], [b'f', b'g', b'h']]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de0f75ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'abcde', b'fgh'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join the characters\n",
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f2a502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4259df7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(94238,), dtype=int64, numpy=array([18, 53, 50, ..., 17, 26, 16], dtype=int64)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "968b97c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "728624f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "f\n",
      "a\n",
      "i\n",
      "r\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18bcb6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46f68a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'F' b'r' b'o' b'm' b' ' b'f' b'a' b'i' b'r' b'e' b's' b't' b' ' b'c'\n",
      " b'r' b'e' b'a' b't' b'u' b'r' b'e' b's' b' ' b'w' b'e' b' ' b'd' b'e'\n",
      " b's' b'i' b'r' b'e' b' ' b'i' b'n' b'c' b'r' b'e' b'a' b's' b'e'], shape=(41,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_len+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "    print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a38ce00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From fairest creatures we desire increase\n",
      ",\n",
      "That thereby beauty's rose might never \n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(2):\n",
    "    print(text_from_ids(seq).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ebc33ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for splitting input and label\n",
    "def split_input_label(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "076d489d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['S', 'h', 'a', 'k', 'e', 's', 'p', 'h', 'e', 'r'], ['h', 'a', 'k', 'e', 's', 'p', 'h', 'e', 'r', 'e'])\n"
     ]
    }
   ],
   "source": [
    "print(split_input_label(list('Shakesphere')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01c18383",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afa63873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: b'From fairest creatures we desire increas'\n",
      "Input: b'rom fairest creatures we desire increase'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(f'Input: {text_from_ids(input_example).numpy()}')\n",
    "    print(f'Input: {text_from_ids(target_example).numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d91d191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(32, 40), dtype=tf.int64, name=None), TensorSpec(shape=(32, 40), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca840db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024\n",
    "\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "583a74e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNNModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn1 = tf.keras.layers.SimpleRNN(rnn_units, return_sequences=True, return_state=True)\n",
    "        self.rnn2 = tf.keras.layers.SimpleRNN(rnn_units, return_sequences=True, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(inputs, training=training)\n",
    "        if states == None:\n",
    "            states = self.rnn1.get_initial_state(x)\n",
    "#         x, states1 = self.rnn1(x, initial_state=states, training=training)\n",
    "        x, states2 = self.rnn2(x, initial_state=states, training=training)\n",
    "        x = self.dense(x)\n",
    "        \n",
    "        if return_state:\n",
    "            return x, states2\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f1dc3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyRNNModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f512e8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 40, 62) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0783f44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_rnn_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  15872     \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      multiple                  0 (unused)\n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    multiple                  1311744   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  63550     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,391,166\n",
      "Trainable params: 1,391,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49630768",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "718aa1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44,  8, 48, 51, 52, 44, 14, 26, 31, 21,  5, 24, 49, 18, 57, 28, 19,\n",
       "       61, 57,  9, 35, 41, 12, 36, 12, 51, 29, 35, 55, 58, 35, 16, 11, 38,\n",
       "       41,  1,  4, 58, 24, 59], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17e05c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'its,\\nWhen I am sometime absent from thy '\n",
      "\n",
      "Output from untrained model:\n",
      " b\"i-mpqiBNTI(LnFvPGzv.Yf?a?pRYtwYD;cf\\n'wLx\"\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input:\\n {text_from_ids(input_example_batch[0]).numpy()}\")\n",
    "print()\n",
    "print(f\"Output from untrained model:\\n {text_from_ids(sampled_indices).numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "867d1504",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7935539e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (32, 40, 62)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.1356616, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5253fcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.530945"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb272a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss, metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8635d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_directory = './training_checkpoints'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_directory, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callbacks = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True,\n",
    "    save_freq=10*64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48651326",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02232e4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "71/71 [==============================] - 9s 107ms/step - loss: 3.0572 - sparse_categorical_accuracy: 0.2095\n",
      "Epoch 2/30\n",
      "71/71 [==============================] - 8s 107ms/step - loss: 2.3541 - sparse_categorical_accuracy: 0.3316\n",
      "Epoch 3/30\n",
      "71/71 [==============================] - 8s 109ms/step - loss: 2.1567 - sparse_categorical_accuracy: 0.3721\n",
      "Epoch 4/30\n",
      "71/71 [==============================] - 8s 106ms/step - loss: 2.0481 - sparse_categorical_accuracy: 0.3952\n",
      "Epoch 5/30\n",
      "71/71 [==============================] - 8s 107ms/step - loss: 1.9515 - sparse_categorical_accuracy: 0.4182\n",
      "Epoch 6/30\n",
      "71/71 [==============================] - 8s 107ms/step - loss: 1.8771 - sparse_categorical_accuracy: 0.4373\n",
      "Epoch 7/30\n",
      "71/71 [==============================] - 8s 106ms/step - loss: 1.8040 - sparse_categorical_accuracy: 0.4540\n",
      "Epoch 8/30\n",
      "71/71 [==============================] - 8s 107ms/step - loss: 1.7432 - sparse_categorical_accuracy: 0.4724\n",
      "Epoch 9/30\n",
      "71/71 [==============================] - 8s 108ms/step - loss: 1.6864 - sparse_categorical_accuracy: 0.4850\n",
      "Epoch 10/30\n",
      "71/71 [==============================] - 9s 117ms/step - loss: 1.6376 - sparse_categorical_accuracy: 0.4982\n",
      "Epoch 11/30\n",
      "71/71 [==============================] - 8s 109ms/step - loss: 1.5886 - sparse_categorical_accuracy: 0.5121\n",
      "Epoch 12/30\n",
      "71/71 [==============================] - 8s 107ms/step - loss: 1.5422 - sparse_categorical_accuracy: 0.5255\n",
      "Epoch 13/30\n",
      "71/71 [==============================] - 8s 108ms/step - loss: 1.4970 - sparse_categorical_accuracy: 0.5374\n",
      "Epoch 14/30\n",
      "71/71 [==============================] - 8s 108ms/step - loss: 1.4530 - sparse_categorical_accuracy: 0.5487\n",
      "Epoch 15/30\n",
      "71/71 [==============================] - 8s 107ms/step - loss: 1.4095 - sparse_categorical_accuracy: 0.5620\n",
      "Epoch 16/30\n",
      "71/71 [==============================] - 8s 107ms/step - loss: 1.3627 - sparse_categorical_accuracy: 0.5755\n",
      "Epoch 17/30\n",
      "71/71 [==============================] - 8s 107ms/step - loss: 1.3183 - sparse_categorical_accuracy: 0.5865\n",
      "Epoch 18/30\n",
      "71/71 [==============================] - 8s 108ms/step - loss: 1.2723 - sparse_categorical_accuracy: 0.5994\n",
      "Epoch 19/30\n",
      "71/71 [==============================] - 9s 119ms/step - loss: 1.2275 - sparse_categorical_accuracy: 0.6139\n",
      "Epoch 20/30\n",
      "71/71 [==============================] - 8s 107ms/step - loss: 1.1725 - sparse_categorical_accuracy: 0.6297\n",
      "Epoch 21/30\n",
      "71/71 [==============================] - 8s 107ms/step - loss: 1.1191 - sparse_categorical_accuracy: 0.6472\n",
      "Epoch 22/30\n",
      "71/71 [==============================] - 8s 107ms/step - loss: 1.0707 - sparse_categorical_accuracy: 0.6617\n",
      "Epoch 23/30\n",
      "71/71 [==============================] - 8s 107ms/step - loss: 1.0123 - sparse_categorical_accuracy: 0.6810\n",
      "Epoch 24/30\n",
      "71/71 [==============================] - 8s 109ms/step - loss: 0.9631 - sparse_categorical_accuracy: 0.6976\n",
      "Epoch 25/30\n",
      "71/71 [==============================] - 8s 107ms/step - loss: 0.9100 - sparse_categorical_accuracy: 0.7161\n",
      "Epoch 26/30\n",
      "71/71 [==============================] - 8s 107ms/step - loss: 0.8459 - sparse_categorical_accuracy: 0.7384\n",
      "Epoch 27/30\n",
      "71/71 [==============================] - 8s 107ms/step - loss: 0.7945 - sparse_categorical_accuracy: 0.7550\n",
      "Epoch 28/30\n",
      "71/71 [==============================] - 9s 118ms/step - loss: 0.7536 - sparse_categorical_accuracy: 0.7687\n",
      "Epoch 29/30\n",
      "71/71 [==============================] - 8s 107ms/step - loss: 0.7019 - sparse_categorical_accuracy: 0.7865\n",
      "Epoch 30/30\n",
      "71/71 [==============================] - 8s 107ms/step - loss: 0.6454 - sparse_categorical_accuracy: 0.8064\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=30, callbacks=[checkpoint_callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba5ad08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad5d7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67e2f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "        skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            # Put a -inf at each bad index.\n",
    "            values=[-float('inf')]*len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            # Match the shape to the vocabulary\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        # Convert strings to token IDs.\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        # Run the model.\n",
    "        # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "        predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                              return_state=True)\n",
    "        # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits/self.temperature\n",
    "        # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # Sample the output logits to generate token IDs.\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        # Return the characters and model state.\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f56fc9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9dff5c09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hrign.\n",
      "And you on smy not my best love Andordw:\n",
      "An who haster soul:  \n",
      "More of this ?\n",
      "You in subjust all in witter, your creater,\n",
      "And beauty slumbosed by the tell.  \n",
      "Freen's eye is sabred with wearned by black should not so breath, but in pleasure of my friend,\n",
      "So long as yet love remembered from leed.\n",
      "Then if desire influenct usbonqunctyed:\n",
      "No march my bust did call thy show,\n",
      "Then it lives it a widow'st waspess that before with all,\n",
      "And more delight,\n",
      "Though me with dey,\n",
      "My self I'll bosd fixst intwomn acquaiving age,\n",
      "Be you will, thy odners reemed,\n",
      "That I should despite hate freeved less?\n",
      "The old aptime time lost did stape their scare thee gright be't of dorpost\n",
      "To lim sigce)\n",
      "As I lived when in thie character,\n",
      "Which hate not false I swear,\n",
      "Lesdows nou.\n",
      "\n",
      "\n",
      "\n",
      "Saye laytle corpentt,  \n",
      "Somesing old thy good rich lips.\n",
      "Howempilich in our oftaris ey\n",
      "So fell my move,\n",
      "And that when thou rest confound,\n",
      "Time did child!\n",
      "Loobs he vich that living thought have nomen's byet,\n",
      "The play oy dead?\n",
      "For thing wored.  \n",
      "Bearing:\n",
      "But what's hate,\n",
      "Hase bast hy foed,\n",
      "From allot?\n",
      "Which should that in older steal thy self thy must and im his fair their shadow'  \n",
      "But then I speing,\n",
      "And weep and cheirer, whending the breath did.\n",
      "Thou canst my self I'll villed,\n",
      "Yet doth those me to be remembered soul,\n",
      "Whuly feeds thee to be ront.\n",
      "When I by me it desire:\n",
      "But it me contend.\n",
      "And you know with thine, me time po coepting own,\n",
      "But should cunterpains,\n",
      "So long as black, and to come with lises  \n",
      "Whe bounterfeit:\n",
      "That year sublied niglains of worful hourted my pleasing,\n",
      "Wherear not cheek the falsely with countentere?\n",
      "And this thy poce to deeds,\n",
      "Even I then dead steep hel.\n",
      "His being foar time's fixe,\n",
      "Which pattern to be did still,\n",
      "Or love you mays of their still, defig timcelled quites desire,\n",
      "When in the remery,\n",
      "Sentund no more blespect my poor beas.\n",
      "The survict with herseash cay.\n",
      "\n",
      "\n",
      "\n",
      "O kine unto her sousel be.\n",
      "\n",
      "\n",
      " onour of forfider:\n",
      "So for their spepress thus in my foother's llain, and befieds with comfort st\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "Run time: 13.538114547729492\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['From fairiest creature'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(2000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "    print(next_char[0].numpy().decode('utf-8'), sep='\\n\\n', end='')\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print()\n",
    "print(\"_\"*100, end=\"\\n\\n\")\n",
    "# print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9828a72c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08562ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTMModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, lstm_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm1 = tf.keras.layers.LSTM(lstm_units, return_sequences=True, return_state=True)\n",
    "        self.lstm2 = tf.keras.layers.LSTM(lstm_units, return_sequences=True, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, inputs, c_state=None, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(inputs, training=training)\n",
    "        if states == None:\n",
    "            states, c_state = self.lstm1.get_initial_state(x)\n",
    "#         x, states1 ,c_state1 = self.lstm1(x, initial_state=[states, c_state], training=training)\n",
    "        x, states2, c_state2 = self.lstm2(x, initial_state=[states, c_state], training=training)\n",
    "        x = self.dense(x)\n",
    "        \n",
    "        if return_state:\n",
    "            return x, [states2, c_state2]\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11fa9eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyLSTMModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    lstm_units=rnn_units\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea1b6b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss, metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a42c3843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "71/71 [==============================] - 13s 65ms/step - loss: 3.1203 - sparse_categorical_accuracy: 0.1906\n",
      "Epoch 2/20\n",
      "71/71 [==============================] - 5s 64ms/step - loss: 2.3950 - sparse_categorical_accuracy: 0.3230\n",
      "Epoch 3/20\n",
      "71/71 [==============================] - 5s 63ms/step - loss: 2.1591 - sparse_categorical_accuracy: 0.3712\n",
      "Epoch 4/20\n",
      "71/71 [==============================] - 5s 64ms/step - loss: 2.0110 - sparse_categorical_accuracy: 0.4048\n",
      "Epoch 5/20\n",
      "71/71 [==============================] - 5s 63ms/step - loss: 1.8934 - sparse_categorical_accuracy: 0.4335\n",
      "Epoch 6/20\n",
      "71/71 [==============================] - 5s 63ms/step - loss: 1.7977 - sparse_categorical_accuracy: 0.4591\n",
      "Epoch 7/20\n",
      "71/71 [==============================] - 6s 81ms/step - loss: 1.7164 - sparse_categorical_accuracy: 0.4786\n",
      "Epoch 8/20\n",
      "71/71 [==============================] - 5s 64ms/step - loss: 1.6452 - sparse_categorical_accuracy: 0.4963\n",
      "Epoch 9/20\n",
      "71/71 [==============================] - 5s 63ms/step - loss: 1.5765 - sparse_categorical_accuracy: 0.5147\n",
      "Epoch 10/20\n",
      "71/71 [==============================] - 5s 63ms/step - loss: 1.5113 - sparse_categorical_accuracy: 0.5321\n",
      "Epoch 11/20\n",
      "71/71 [==============================] - 5s 64ms/step - loss: 1.4430 - sparse_categorical_accuracy: 0.5503\n",
      "Epoch 12/20\n",
      "71/71 [==============================] - 5s 64ms/step - loss: 1.3658 - sparse_categorical_accuracy: 0.5726\n",
      "Epoch 13/20\n",
      "71/71 [==============================] - 5s 65ms/step - loss: 1.2825 - sparse_categorical_accuracy: 0.5969\n",
      "Epoch 14/20\n",
      "71/71 [==============================] - 5s 67ms/step - loss: 1.1863 - sparse_categorical_accuracy: 0.6273\n",
      "Epoch 15/20\n",
      "71/71 [==============================] - 5s 67ms/step - loss: 1.0757 - sparse_categorical_accuracy: 0.6634\n",
      "Epoch 16/20\n",
      "71/71 [==============================] - 6s 84ms/step - loss: 0.9500 - sparse_categorical_accuracy: 0.7064\n",
      "Epoch 17/20\n",
      "71/71 [==============================] - 5s 65ms/step - loss: 0.8136 - sparse_categorical_accuracy: 0.7572\n",
      "Epoch 18/20\n",
      "71/71 [==============================] - 5s 66ms/step - loss: 0.6725 - sparse_categorical_accuracy: 0.8102\n",
      "Epoch 19/20\n",
      "71/71 [==============================] - 5s 67ms/step - loss: 0.5402 - sparse_categorical_accuracy: 0.8562\n",
      "Epoch 20/20\n",
      "71/71 [==============================] - 5s 64ms/step - loss: 0.4258 - sparse_categorical_accuracy: 0.8944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17c16c9ddf0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=20, callbacks=checkpoint_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24cd4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "        skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            # Put a -inf at each bad index.\n",
    "            values=[-float('inf')]*len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            # Match the shape to the vocabulary\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None, c_state=None):\n",
    "        # Convert strings to token IDs.\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        # Run the model.\n",
    "        # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "        predicted_logits, [states, c_state] = self.model(inputs=input_ids, states=states, c_state=c_state,\n",
    "                                              return_state=True)\n",
    "        # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits/self.temperature\n",
    "        # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # Sample the output logits to generate token IDs.\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        # Return the characters and model state.\n",
    "        return predicted_chars, [states, c_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41d83544",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc605a0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in hy shadow in his torter,\n",
      "The spepit title of hy life hid soil this beauty is summer's grace,\n",
      "And heary I lost, the olates you canny\n",
      "An bllows all lively paces, I sow, that thou dost wake elsewhere,\n",
      "Though wauting posy, youth not so much hath a tarve autuse their sprite,\n",
      "What canOw I swear it out every than time?\n",
      "For that scire of brane dhymen, and therein subling hand,\n",
      "Art love in thou wilt befrives to ither-salve to misure me,\n",
      "And every change agising,\n",
      "On storn befored, and night:  \n",
      "Of Though west with own wordand primake image wirds comblexy Creal,\n",
      "Came thee bast and wrinkles flame should aloue,\n",
      "That eyes cange I were not know my heaven thems in thy beauty do I beckay.\n",
      "\n",
      "\n",
      "'Tife thou shalt not boast that id a fam for weter-say,  \n",
      "Nor hawe and I precious juilt be but time decay,\n",
      "Of place whereof may nightly but thy die, must exconst,\n",
      "Lath give an limitious lives in thy bud, to-losied phare,\n",
      "I must I one then do mine eye is in my sing,\n",
      "And the frillich first thou haster vistor on the stores of thou hast before wand grows would will may dead,\n",
      "Mad in all my poor lips with pleas rage of praise, which behind a preak of youbd.\n",
      "For I am shamed, in such with that reason hat other made,\n",
      "By bland so secject My thoughts (sweep and proilith thee,\n",
      "Mill nothing barr trather, and rich-pleasure that is old akong:\n",
      "That is for my side sweet best exceeks the valys are be tender mighing me, when I do believe much:\n",
      "Ore all the treasure of the slore, of thuse throwels in the beauty of torments:\n",
      "So blame the gaved them true pirect to deceived by their remase,\n",
      "Mike away aline bade of thence's knowh heaveng creation inlearied:\n",
      "Ag wither to mine ears, when thou be denioned pawning raoked, and in place, and then that love is spent.\n",
      "\n",
      "\n",
      "\n",
      "What's in the bland so confents of after I am not pasiou in jest,\n",
      "That cheek it alfere endswer of a leasured for thy heart,  \n",
      "My sicknoll warring to hate, with thee, must not some wit.\n",
      "O flowers inthie that which like two spirits do spend;\n",
      "Nore to thee may ch\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "Run time: 18.279967546463013\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states, c_state = None, None\n",
    "next_char = tf.constant(['From the fairiest creatures'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(2000):\n",
    "    next_char, [states, c_state] = one_step_model.generate_one_step(next_char, states=states, c_state=c_state)\n",
    "    result.append(next_char)\n",
    "    print(next_char[0].numpy().decode('utf-8'), sep='\\n\\n', end='')\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print()\n",
    "print(\"_\"*100, end=\"\\n\\n\")\n",
    "# print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21555cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
